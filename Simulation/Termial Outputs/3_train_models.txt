Training data owner A's dataset on cuda:0 ...
Sequential(
  (0): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (1): Linear(in_features=768, out_features=128, bias=True)
  (2): GELU()
  (3): Linear(in_features=128, out_features=6, bias=True)
)
Batch image shape: [32, 768]
Batch label shape: [32]
Model output shape: [32, 6]
100%|████████████████████████████████████████████████████████████████████████████████| 422/422 [10:44<00:00,  1.53s/it]
[  1:10 ]       loss=0.394,             acc=11589/13500=0.858
100%|████████████████████████████████████████████████████████████████████████████████| 422/422 [11:21<00:00,  1.62s/it]
[  2:10 ]       loss=0.288,             acc=12083/13500=0.895
100%|████████████████████████████████████████████████████████████████████████████████| 422/422 [16:30<00:00,  2.35s/it]
[  3:10 ]       loss=0.260,             acc=12217/13500=0.905
100%|████████████████████████████████████████████████████████████████████████████████| 422/422 [17:31<00:00,  2.49s/it]
[  4:10 ]       loss=0.254,             acc=12279/13500=0.910
100%|████████████████████████████████████████████████████████████████████████████████| 422/422 [17:25<00:00,  2.48s/it]
[  5:10 ]       loss=0.234,             acc=12324/13500=0.913
100%|████████████████████████████████████████████████████████████████████████████████| 422/422 [16:28<00:00,  2.34s/it]
[  6:10 ]       loss=0.222,             acc=12430/13500=0.921
100%|████████████████████████████████████████████████████████████████████████████████| 422/422 [20:59<00:00,  2.98s/it]
[  7:10 ]       loss=0.222,             acc=12444/13500=0.922
100%|████████████████████████████████████████████████████████████████████████████████| 422/422 [16:43<00:00,  2.38s/it]
[  8:10 ]       loss=0.223,             acc=12446/13500=0.922
100%|████████████████████████████████████████████████████████████████████████████████| 422/422 [16:12<00:00,  2.30s/it]
[  9:10 ]       loss=0.218,             acc=12396/13500=0.918
100%|████████████████████████████████████████████████████████████████████████████████| 422/422 [16:04<00:00,  2.29s/it]
[ 10:10 ]       loss=0.199,             acc=12506/13500=0.926




Training data owner B's dataset on cpu ...
Sequential(
  (0): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (1): Linear(in_features=768, out_features=128, bias=True)
  (2): GELU()
  (3): Linear(in_features=128, out_features=3, bias=True)
)
Batch image shape: [32, 768]
Batch label shape: [32]
Model output shape: [32, 3]
100%|████████████████████████████████████████████████████████████████████████████████| 185/185 [52:40<00:00, 17.09s/it]
[  1:3 ]        loss=0.350,             acc=5076/5900=0.860
100%|████████████████████████████████████████████████████████████████████████████████| 185/185 [59:11<00:00, 19.20s/it]
[  2:3 ]        loss=0.244,             acc=5343/5900=0.906
100%|████████████████████████████████████████████████████████████████████████████████| 185/185 [29:57<00:00,  9.72s/it]
[  3:3 ]        loss=0.239,             acc=5355/5900=0.908




Training data owner C's dataset on cuda:0 ...
Sequential(
  (0): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (1): Linear(in_features=768, out_features=256, bias=True)
  (2): GELU()
  (3): Linear(in_features=256, out_features=4, bias=True)
)
Batch image shape: [32, 768]
Batch label shape: [32]
Model output shape: [32, 4]
100%|████████████████████████████████████████████████████████████████████████████████| 166/166 [03:43<00:00,  1.34s/it]
[  1:10 ]       loss=0.379,             acc=4586/5300=0.865
100%|████████████████████████████████████████████████████████████████████████████████| 166/166 [03:52<00:00,  1.40s/it]
[  2:10 ]       loss=0.280,             acc=4770/5300=0.900
100%|████████████████████████████████████████████████████████████████████████████████| 166/166 [03:54<00:00,  1.41s/it]
[  3:10 ]       loss=0.243,             acc=4851/5300=0.915
100%|████████████████████████████████████████████████████████████████████████████████| 166/166 [03:53<00:00,  1.40s/it]
[  4:10 ]       loss=0.233,             acc=4863/5300=0.918
100%|████████████████████████████████████████████████████████████████████████████████| 166/166 [03:54<00:00,  1.41s/it]
[  5:10 ]       loss=0.221,             acc=4881/5300=0.921
100%|████████████████████████████████████████████████████████████████████████████████| 166/166 [03:54<00:00,  1.41s/it]
[  6:10 ]       loss=0.203,             acc=4912/5300=0.927
100%|████████████████████████████████████████████████████████████████████████████████| 166/166 [04:07<00:00,  1.49s/it]
[  7:10 ]       loss=0.207,             acc=4901/5300=0.925
100%|████████████████████████████████████████████████████████████████████████████████| 166/166 [03:56<00:00,  1.43s/it]
[  8:10 ]       loss=0.183,             acc=4924/5300=0.929
100%|████████████████████████████████████████████████████████████████████████████████| 166/166 [03:54<00:00,  1.42s/it]
[  9:10 ]       loss=0.182,             acc=4937/5300=0.932
100%|████████████████████████████████████████████████████████████████████████████████| 166/166 [03:53<00:00,  1.40s/it]
[ 10:10 ]       loss=0.176,             acc=4961/5300=0.936




Training data owner D's dataset on cuda:0 ...
Sequential(
  (0): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (1): Linear(in_features=768, out_features=128, bias=True)
  (2): GELU()
  (3): Linear(in_features=128, out_features=2, bias=True)
)
Batch image shape: [32, 768]
Batch label shape: [32]
Model output shape: [32, 2]
100%|████████████████████████████████████████████████████████████████████████████████| 113/113 [03:12<00:00,  1.71s/it]
[  1:10 ]       loss=0.266,             acc=3189/3600=0.886
100%|████████████████████████████████████████████████████████████████████████████████| 113/113 [03:54<00:00,  2.08s/it]
[  2:10 ]       loss=0.191,             acc=3301/3600=0.917
100%|████████████████████████████████████████████████████████████████████████████████| 113/113 [03:53<00:00,  2.07s/it]
[  3:10 ]       loss=0.189,             acc=3340/3600=0.928
100%|████████████████████████████████████████████████████████████████████████████████| 113/113 [03:52<00:00,  2.06s/it]
[  4:10 ]       loss=0.193,             acc=3304/3600=0.918
100%|████████████████████████████████████████████████████████████████████████████████| 113/113 [03:44<00:00,  1.99s/it]
[  5:10 ]       loss=0.173,             acc=3338/3600=0.927
100%|████████████████████████████████████████████████████████████████████████████████| 113/113 [03:47<00:00,  2.02s/it]
[  6:10 ]       loss=0.150,             acc=3376/3600=0.938
100%|████████████████████████████████████████████████████████████████████████████████| 113/113 [03:58<00:00,  2.11s/it]
[  7:10 ]       loss=0.172,             acc=3357/3600=0.932
100%|████████████████████████████████████████████████████████████████████████████████| 113/113 [03:55<00:00,  2.08s/it]
[  8:10 ]       loss=0.153,             acc=3362/3600=0.934
100%|████████████████████████████████████████████████████████████████████████████████| 113/113 [04:02<00:00,  2.14s/it]
[  9:10 ]       loss=0.142,             acc=3391/3600=0.942
100%|████████████████████████████████████████████████████████████████████████████████| 113/113 [03:51<00:00,  2.05s/it]
[ 10:10 ]       loss=0.148,             acc=3384/3600=0.940




Training data owner E's dataset on cuda:0 ...
Sequential(
  (0): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (1): Linear(in_features=768, out_features=128, bias=True)
  (2): GELU()
  (3): Linear(in_features=128, out_features=64, bias=True)
  (4): GELU()
  (5): Linear(in_features=64, out_features=4, bias=True)
)
Batch image shape: [32, 768]
Batch label shape: [32]
Model output shape: [32, 4]
100%|████████████████████████████████████████████████████████████████████████████████| 122/122 [02:46<00:00,  1.37s/it]
[  1:10 ]       loss=0.473,             acc=3240/3900=0.831
100%|████████████████████████████████████████████████████████████████████████████████| 122/122 [02:53<00:00,  1.42s/it]
[  2:10 ]       loss=0.298,             acc=3465/3900=0.888
100%|████████████████████████████████████████████████████████████████████████████████| 122/122 [02:52<00:00,  1.42s/it]
[  3:10 ]       loss=0.255,             acc=3538/3900=0.907
100%|████████████████████████████████████████████████████████████████████████████████| 122/122 [02:51<00:00,  1.41s/it]
[  4:10 ]       loss=0.249,             acc=3552/3900=0.911
100%|████████████████████████████████████████████████████████████████████████████████| 122/122 [02:51<00:00,  1.41s/it]
[  5:10 ]       loss=0.226,             acc=3585/3900=0.919
100%|████████████████████████████████████████████████████████████████████████████████| 122/122 [02:52<00:00,  1.41s/it]
[  6:10 ]       loss=0.220,             acc=3578/3900=0.917
100%|████████████████████████████████████████████████████████████████████████████████| 122/122 [02:51<00:00,  1.40s/it]
[  7:10 ]       loss=0.209,             acc=3593/3900=0.921
100%|████████████████████████████████████████████████████████████████████████████████| 122/122 [02:53<00:00,  1.42s/it]
[  8:10 ]       loss=0.197,             acc=3614/3900=0.927
100%|████████████████████████████████████████████████████████████████████████████████| 122/122 [02:51<00:00,  1.41s/it]
[  9:10 ]       loss=0.193,             acc=3622/3900=0.929
100%|████████████████████████████████████████████████████████████████████████████████| 122/122 [02:50<00:00,  1.40s/it]
[ 10:10 ]       loss=0.177,             acc=3652/3900=0.936




Training data owner F's dataset on cuda:0 ...
Sequential(
  (0): Linear(in_features=768, out_features=128, bias=True)
  (1): GELU()
  (2): Linear(in_features=128, out_features=3, bias=True)
)
Batch image shape: [32, 768]
Batch label shape: [32]
Model output shape: [32, 3]
100%|████████████████████████████████████████████████████████████████████████████████| 194/194 [06:20<00:00,  1.96s/it]
[  1:10 ]       loss=0.459,             acc=5181/6200=0.836
100%|████████████████████████████████████████████████████████████████████████████████| 194/194 [06:35<00:00,  2.04s/it]
[  2:10 ]       loss=0.322,             acc=5443/6200=0.878
100%|████████████████████████████████████████████████████████████████████████████████| 194/194 [06:38<00:00,  2.05s/it]
[  3:10 ]       loss=0.305,             acc=5452/6200=0.879
100%|████████████████████████████████████████████████████████████████████████████████| 194/194 [06:34<00:00,  2.03s/it]
[  4:10 ]       loss=0.284,             acc=5508/6200=0.888
100%|████████████████████████████████████████████████████████████████████████████████| 194/194 [06:55<00:00,  2.14s/it]
[  5:10 ]       loss=0.261,             acc=5530/6200=0.892
100%|████████████████████████████████████████████████████████████████████████████████| 194/194 [06:36<00:00,  2.04s/it]
[  6:10 ]       loss=0.250,             acc=5543/6200=0.894
100%|████████████████████████████████████████████████████████████████████████████████| 194/194 [06:35<00:00,  2.04s/it]
[  7:10 ]       loss=0.235,             acc=5609/6200=0.905
100%|████████████████████████████████████████████████████████████████████████████████| 194/194 [06:35<00:00,  2.04s/it]
[  8:10 ]       loss=0.243,             acc=5560/6200=0.897
100%|████████████████████████████████████████████████████████████████████████████████| 194/194 [06:44<00:00,  2.09s/it]
[  9:10 ]       loss=0.228,             acc=5632/6200=0.908
100%|████████████████████████████████████████████████████████████████████████████████| 194/194 [06:32<00:00,  2.02s/it]
[ 10:10 ]       loss=0.226,             acc=5631/6200=0.908




Training data owner G's dataset on cuda:0 ...
Sequential(
  (0): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (1): Linear(in_features=768, out_features=256, bias=True)
  (2): GELU()
  (3): Linear(in_features=256, out_features=64, bias=True)
  (4): GELU()
  (5): Linear(in_features=64, out_features=2, bias=True)
)
Batch image shape: [32, 768]
Batch label shape: [32]
Model output shape: [32, 2]
100%|██████████████████████████████████████████████████████████████████████████████████| 91/91 [01:56<00:00,  1.28s/it]
[  1:15 ]       loss=0.260,             acc=2586/2900=0.892
100%|██████████████████████████████████████████████████████████████████████████████████| 91/91 [02:04<00:00,  1.36s/it]
[  2:15 ]       loss=0.177,             acc=2683/2900=0.925
100%|██████████████████████████████████████████████████████████████████████████████████| 91/91 [02:02<00:00,  1.35s/it]
[  3:15 ]       loss=0.165,             acc=2705/2900=0.933
100%|██████████████████████████████████████████████████████████████████████████████████| 91/91 [02:02<00:00,  1.34s/it]
[  4:15 ]       loss=0.141,             acc=2745/2900=0.947
100%|██████████████████████████████████████████████████████████████████████████████████| 91/91 [02:05<00:00,  1.38s/it]
[  5:15 ]       loss=0.139,             acc=2733/2900=0.942
100%|██████████████████████████████████████████████████████████████████████████████████| 91/91 [02:10<00:00,  1.44s/it]
[  6:15 ]       loss=0.131,             acc=2758/2900=0.951
100%|██████████████████████████████████████████████████████████████████████████████████| 91/91 [02:06<00:00,  1.39s/it]
[  7:15 ]       loss=0.132,             acc=2752/2900=0.949
100%|██████████████████████████████████████████████████████████████████████████████████| 91/91 [02:06<00:00,  1.39s/it]
[  8:15 ]       loss=0.124,             acc=2749/2900=0.948
100%|██████████████████████████████████████████████████████████████████████████████████| 91/91 [02:06<00:00,  1.39s/it]
[  9:15 ]       loss=0.125,             acc=2750/2900=0.948
100%|██████████████████████████████████████████████████████████████████████████████████| 91/91 [02:06<00:00,  1.39s/it]
[ 10:15 ]       loss=0.123,             acc=2758/2900=0.951
100%|██████████████████████████████████████████████████████████████████████████████████| 91/91 [02:05<00:00,  1.38s/it]
[ 11:15 ]       loss=0.101,             acc=2783/2900=0.960
100%|██████████████████████████████████████████████████████████████████████████████████| 91/91 [02:07<00:00,  1.40s/it]
[ 12:15 ]       loss=0.101,             acc=2781/2900=0.959
100%|██████████████████████████████████████████████████████████████████████████████████| 91/91 [02:04<00:00,  1.37s/it]
[ 13:15 ]       loss=0.095,             acc=2800/2900=0.966
100%|██████████████████████████████████████████████████████████████████████████████████| 91/91 [02:06<00:00,  1.38s/it]
[ 14:15 ]       loss=0.098,             acc=2791/2900=0.962
100%|██████████████████████████████████████████████████████████████████████████████████| 91/91 [02:06<00:00,  1.39s/it]
[ 15:15 ]       loss=0.098,             acc=2791/2900=0.962




Training data owner T1's dataset on cuda:0 ...
Sequential(
  (0): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (1): Linear(in_features=768, out_features=32, bias=True)
  (2): GELU()
  (3): Linear(in_features=32, out_features=2, bias=True)
)
Batch image shape: [32, 768]
Batch label shape: [32]
Model output shape: [32, 2]
100%|██████████████████████████████████████████████████████████████████████████████████| 82/82 [01:45<00:00,  1.29s/it]
[  1:3 ]        loss=0.295,             acc=2275/2600=0.875
100%|██████████████████████████████████████████████████████████████████████████████████| 82/82 [01:55<00:00,  1.40s/it]
[  2:3 ]        loss=0.217,             acc=2347/2600=0.903
100%|██████████████████████████████████████████████████████████████████████████████████| 82/82 [01:54<00:00,  1.40s/it]
[  3:3 ]        loss=0.183,             acc=2392/2600=0.920




Training data owner T2's dataset on cuda:0 ...
Sequential(
  (0): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (1): Linear(in_features=768, out_features=64, bias=True)
  (2): GELU()
  (3): Linear(in_features=64, out_features=2, bias=True)
)
Batch image shape: [32, 768]
Batch label shape: [32]
Model output shape: [32, 2]
100%|████████████████████████████████████████████████████████████████████████████████| 160/160 [03:33<00:00,  1.33s/it]
[  1:10 ]       loss=0.252,             acc=4515/5100=0.885
100%|████████████████████████████████████████████████████████████████████████████████| 160/160 [03:51<00:00,  1.45s/it]
[  2:10 ]       loss=0.190,             acc=4698/5100=0.921
100%|████████████████████████████████████████████████████████████████████████████████| 160/160 [03:34<00:00,  1.34s/it]
[  3:10 ]       loss=0.166,             acc=4738/5100=0.929
100%|████████████████████████████████████████████████████████████████████████████████| 160/160 [03:35<00:00,  1.34s/it]
[  4:10 ]       loss=0.161,             acc=4762/5100=0.934
100%|████████████████████████████████████████████████████████████████████████████████| 160/160 [03:36<00:00,  1.35s/it]
[  5:10 ]       loss=0.149,             acc=4774/5100=0.936
100%|████████████████████████████████████████████████████████████████████████████████| 160/160 [03:34<00:00,  1.34s/it]
[  6:10 ]       loss=0.149,             acc=4813/5100=0.944
100%|████████████████████████████████████████████████████████████████████████████████| 160/160 [03:34<00:00,  1.34s/it]
[  7:10 ]       loss=0.131,             acc=4825/5100=0.946
100%|████████████████████████████████████████████████████████████████████████████████| 160/160 [03:34<00:00,  1.34s/it]
[  8:10 ]       loss=0.125,             acc=4853/5100=0.952
100%|████████████████████████████████████████████████████████████████████████████████| 160/160 [03:34<00:00,  1.34s/it]
[  9:10 ]       loss=0.123,             acc=4843/5100=0.950
100%|████████████████████████████████████████████████████████████████████████████████| 160/160 [03:34<00:00,  1.34s/it]
[ 10:10 ]       loss=0.127,             acc=4836/5100=0.948




Training data owner T3's dataset on cuda:0 ...
Sequential(
  (0): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (1): Linear(in_features=768, out_features=1024, bias=True)
  (2): GELU()
  (3): Linear(in_features=1024, out_features=256, bias=True)
  (4): GELU()
  (5): Linear(in_features=256, out_features=64, bias=True)
  (6): GELU()
  (7): Linear(in_features=64, out_features=2, bias=True)
)
Batch image shape: [32, 768]
Batch label shape: [32]
Model output shape: [32, 2]
100%|██████████████████████████████████████████████████████████████████████████████████| 94/94 [02:02<00:00,  1.30s/it]
[  1:3 ]        loss=0.343,             acc=2541/3000=0.847
100%|██████████████████████████████████████████████████████████████████████████████████| 94/94 [02:03<00:00,  1.31s/it]
[  2:3 ]        loss=0.300,             acc=2572/3000=0.857
100%|██████████████████████████████████████████████████████████████████████████████████| 94/94 [02:08<00:00,  1.36s/it]
[  3:3 ]        loss=0.276,             acc=2650/3000=0.883


